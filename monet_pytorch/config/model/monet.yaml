# @package _global_

optimizer:
  _target_: torch.optim.rmsprop.RMSprop
  centered: true
  lr: 0.0001


model:
  _target_: monet_pytorch.model.Monet
  height: ${dataset.height}
  width: ${dataset.width}
  num_slots: ${dataset.max_num_objects}
  name: monet
  bg_sigma: 0.09
  fg_sigma: 0.11
  num_blocks_unet: 5
  beta_kl: 0.5
  gamma: 0.5
  latent_size: 16
  encoder_config:
    channels: [32, 32, 64, 64]
    kernels: 3
    strides: 2
    paddings: 0
    input_channels: 4
    batchnorms: true
    bn_affines: false
    activations: relu
    mlp_hidden_size: 256
    mlp_output_size: 32  # latent_size * 2
  decoder_config:
    w_broadcast: ${add:${dataset.width},8}
    h_broadcast: ${add:${dataset.height},8}
    input_channels: 18 # latent size + 2
    channels: [32, 32, 64, 64, 4]  # last is 4 channels because rgb (3) + mask (1)
    kernels: [3, 3, 3, 3, 1]
    paddings: 0
    activations: [relu, relu, relu, relu, null]  #null means no activation function no activation
    batchnorms: [true, true, true, true, false]
    bn_affines: [false, false, false, false, false]
