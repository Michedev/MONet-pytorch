# @package _global_
model:
  encoder:
    _target_: torch.nn.Sequential
    _args_:
      - _target_: monet_pytorch.template.sequential_cnn.make_sequential_cnn_from_config
        channels: [ 32, 32, 64, 64 ]
        kernels: 3
        strides: 2
        paddings: 0
        input_channels: 4
        batchnorms: true
        bn_affines: false
        activations: relu
      - _target_: torch.nn.Flatten
        start_dim: 1
      - _target_: torch.nn.Linear
        in_features: 3136
        out_features: 256
      - _target_: torch.nn.ReLU
      - _target_: torch.nn.Linear
        in_features: 256
        out_features: ${prod:${model.latent_size},2}
  unet:
    num_blocks: 6